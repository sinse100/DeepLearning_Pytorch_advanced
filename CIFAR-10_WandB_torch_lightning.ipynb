{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "82e4aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55994b66",
   "metadata": {},
   "source": [
    "### WandB 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "644a7a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b5d47",
   "metadata": {},
   "source": [
    "### 데이터 모듈 생성 (pl.LightningDataModule 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bf0818ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10DataModule(pl.LightningDataModule):      ## 데이터 모듈은 반드시, LightningDataModule 을 상속토록 함.\n",
    "    def __init__(self, batch_size, data_path = './data'):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path           ## 데이터 셋 디렉토리\n",
    "        self.batch_size = batch_size       ## 1 batch = batch_size 개 만큼의 데이터 셋으로 구성 \n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        self.dims = (3, 32, 32)  ## CIFAR10 데이터 셋의 Shape (32*32*3)\n",
    "    \n",
    "    ## prepare_data : CIFAR10 데이터 셋 다운로드\n",
    "    def prepare_data(self):\n",
    "        CIFAR10(self.data_path, train=True, download=True)  ## Train 데이터 셋 다운로드\n",
    "        CIFAR10(self.data_path, train=False, download=True) ## Test 데이터 셋 다운로드\n",
    "    \n",
    "    ## setup : 다운로드된 데이터 셋들에 Transform 적용하고,, Train, Validation, Test 데이터 셋으로 분리 \n",
    "    def setup(self):\n",
    "        cifar_full = CIFAR10(self.data_path, train=True, transform=self.transform)\n",
    "        self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000]) # Train, Validation 데이터 셋 분리\n",
    "        self.cifar_test = CIFAR10(self.data_path, train=False, transform=self.transform) # Test 데이터 셋 \n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=self.batch_size)            \n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=self.batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74290a6b",
   "metadata": {},
   "source": [
    "### LightningModule 통한 System (Model 과 유사) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9601e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(pl.LightningModule):   ## LightningModule 을 반드시 상속\n",
    "    def __init__(self, lr=0.001):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 체크포인트까지의 값들을 저장하기 위해 사용(log hyperparameters)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        ## Learning Rate 설정\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        ## 3  (in_channels) : Channel 수 3개 (R,G,B)\n",
    "        ## 32 (out_channels) : Output 의 Channel 수 32 개 (따라서, 3*3*3 의 이미지 필터가 총 32개 존재)\n",
    "        ## 3  (kernel_size) : Kernel 사이즈 3*3\n",
    "        ## 1  (Stride) : 커널 윈도우 Stride 1\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        ## 2 (kernel size)\n",
    "        ## 2 (Stride)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        ## 32  (in_channels) : Channel 수 32개 \n",
    "        ## 32 (out_channels) : Output 의 Channel 수 32 개 (따라서, 32*3*3 의 이미지 필터가 총 32개 존재)\n",
    "        ## 3  (kernel_size) : Kernel 사이즈 3*3\n",
    "        ## 1  (Stride) : 커널 윈도우 Stride 1\n",
    "\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        ## 32  (in_channels) : Channel 수 32개 \n",
    "        ## 64 (out_channels) : Output 의 Channel 수 64 개 (따라서, 32*3*3 의 이미지 필터가 총 64개 존재)\n",
    "        ## 3 (kernel_size) : Kernel 사이즈 (3*3)\n",
    "        ## 1 (Stride)\n",
    "        \n",
    "        \n",
    "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
    "        ## 64 (in_channels) : Channel 수 64개\n",
    "        ## 64 (out_channels) : Output 의 Channel 수 64 개 (따라서, 64*3*3 의 이미지 필터가 총 64개 존재)\n",
    "        ## 3 (kernel_size)\n",
    "        ## 1 (Stride)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        ## 2 (kernel size)\n",
    "        ## 2 (Stride)\n",
    "        \n",
    "        self.fc1 = nn.Linear(5 * 5 * 64, 512)                    ##\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "\n",
    "        \n",
    "    # _forward_features : Conv2d + MaxPoll2d 계층 통과 직후의 Tensor 를 반환\n",
    "    def _forward_features(self, x):\n",
    "        x = F.relu(self.conv1(x))              ## 첫번째 Conv2d 계층 통과 -> ReLU   \n",
    "                                               ## (output shape (H,W,C) :  30 * 30 * 32)\n",
    "        x = self.pool1(F.relu(self.conv2(x)))  ## 두번째 Conv2d 계층 통과 -> ReLU -> 첫번째 MaxPool2d \n",
    "                                               ## (output shape (H,W,C) :  14 * 14 * 32)\n",
    "        x = F.relu(self.conv3(x))              ## 세번째 Conv2d 계층 통과 -> ReLU \n",
    "                                               ## (output shape (H,W,C) :  12 * 12 * 64)\n",
    "        x = self.pool2(F.relu(self.conv4(x)))  ## 마지막 Conv2d 계층 통과 -> ReLU -> 두번째 MaxPool2d\n",
    "                                               ## (output shape (H,W,C) :  5 * 5 * 64) \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)          ## Conv2d + MaxPool2d 계층 통과\n",
    "        x = x.view(x.size(0), -1)              ## Tensor 선형화\n",
    "        x = F.relu(self.fc1(x))                ## 첫번째 Affine 계층 통과 -> ReLU \n",
    "        x = F.relu(self.fc2(x))                ## 두번째 Affine 계층 통과 -> ReLU\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)  ## 세번째 Affine 계층 통과 -> SoftMax\n",
    "       \n",
    "        return x        \n",
    "    \n",
    "    ##\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # training metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    ##\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    ##\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    ## Optimizer 설정 https://neelesh609.github.io/cifar10/ 링크 참고하여, Adam 을 통한 Back-Prop 을 했을 때 성능이 가장 높았음을 참고\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "## https://github.com/rubentea16/pl-mnist/blob/master/model.py 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3cdfe",
   "metadata": {},
   "source": [
    "### 데이터셋 준비/로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6858783b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CIFAR10DataModule(batch_size=32)       ## CIFAR-10 데이터셋 설정 (1 Batch Size, Directory, Class 수, 1 Data Sample Shape)\n",
    "data_set.prepare_data()                           ## CIFAR-10 데이터셋 다운로드\n",
    "data_set.setup()                                  ## Train, Test, Validation 데이터 셋으로 분리\n",
    "\n",
    "val_samples = next(iter(data_set.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76907d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/2017125033/wandb/run-20220929_144426-3jz852bg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sinse100/2017125033_GeonWooBaek_pytorch_lightning_Cifar10/runs/3jz852bg\" target=\"_blank\">gentle-wave-8</a></strong> to <a href=\"https://wandb.ai/sinse100/2017125033_GeonWooBaek_pytorch_lightning_Cifar10\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type      | Params\n",
      "---------------------------------------\n",
      "0 | conv1    | Conv2d    | 896   \n",
      "1 | pool1    | MaxPool2d | 0     \n",
      "2 | conv2    | Conv2d    | 9.2 K \n",
      "3 | conv3    | Conv2d    | 18.5 K\n",
      "4 | conv4    | Conv2d    | 36.9 K\n",
      "5 | pool2    | MaxPool2d | 0     \n",
      "6 | fc1      | Linear    | 819 K \n",
      "7 | fc2      | Linear    | 65.7 K\n",
      "8 | fc3      | Linear    | 1.3 K \n",
      "9 | accuracy | Accuracy  | 0     \n",
      "---------------------------------------\n",
      "952 K     Trainable params\n",
      "0         Non-trainable params\n",
      "952 K     Total params\n",
      "3.809     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d206b4152bec40f9abf0e129f0cb6083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/jovyan/2017125033/2017125033_GeonWooBaek_pytorch_lightning_Cifar10/3jz852bg/checkpoints/epoch=7-step=11255.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from checkpoint at /home/jovyan/2017125033/2017125033_GeonWooBaek_pytorch_lightning_Cifar10/3jz852bg/checkpoints/epoch=7-step=11255.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65fd2e6be7c494cbeb8a1829e933063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.7293999791145325, 'test_loss': 0.9915676712989807}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▆▇▇██</td></tr><tr><td>train_acc_step</td><td>▂▃▁▁▄▃▄▃▅▅▅▄▅▆▆▅▆▅▆▇▆▆▆▆▆▅▆▇▆▆▇▇▆▅▅▇█▇█▆</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▇▆█▅▇▄▄▄▅▅▃▃▅▃▄▃▃▃▃▂▂▃▄▄▂▃▃▃▃▃▄▄▂▁▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▅▇▇████</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>8</td></tr><tr><td>test_acc</td><td>0.7294</td></tr><tr><td>test_loss</td><td>0.99157</td></tr><tr><td>train_acc_epoch</td><td>0.89184</td></tr><tr><td>train_acc_step</td><td>0.9375</td></tr><tr><td>train_loss_epoch</td><td>0.30422</td></tr><tr><td>train_loss_step</td><td>0.22703</td></tr><tr><td>trainer/global_step</td><td>11256</td></tr><tr><td>val_acc</td><td>0.7298</td></tr><tr><td>val_loss</td><td>1.00187</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gentle-wave-8</strong>: <a href=\"https://wandb.ai/sinse100/2017125033_GeonWooBaek_pytorch_lightning_Cifar10/runs/3jz852bg\" target=\"_blank\">https://wandb.ai/sinse100/2017125033_GeonWooBaek_pytorch_lightning_Cifar10/runs/3jz852bg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220929_144426-3jz852bg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJ_NAME = '2017125033_GeonWooBaek_pytorch_lightning_Cifar10'\n",
    "\n",
    "## Lightning Model 초기화 \n",
    "model = ToyModel(data_set.size())\n",
    "\n",
    "# Wandb Logger 초기화\n",
    "wandb_logger = WandbLogger(project=PROJ_NAME, job_type='train')\n",
    "\n",
    "# Initialize Callbacks\n",
    "early_stop = pl.callbacks.EarlyStopping(monitor=\"val_loss\")\n",
    "checkpt = pl.callbacks.ModelCheckpoint()\n",
    "\n",
    "# Trainer 초기화 (Epoch 10 회, 1개의 GPU 사용(2개 사용가능한데, Jupyter 에서는 DDP 오류),)\n",
    "trainer = pl.Trainer(max_epochs=10, gpus=1, logger=wandb_logger,callbacks=[early_stop,checkpt])\n",
    "\n",
    "# 모델 학습 시작\n",
    "trainer.fit(model, data_set)\n",
    "# 모델 테스트 시작 \n",
    "trainer.test(dataloaders=data_set.test_dataloader())\n",
    "\n",
    "# Close wandb run\n",
    "wandb.finish()\n",
    "\n",
    "\n",
    "## https://wandb.ai/wandb_fc/korean/reports/Weights-Biases-Pytorch-Lightning---VmlldzozNzAxOTg 코드 참고\n",
    "## https://wikidocs.net/157552 코드 참고"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.10.0-py3.8-cuda11.3",
   "language": "python",
   "name": "torch1.10.0-py3.8-cuda11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
